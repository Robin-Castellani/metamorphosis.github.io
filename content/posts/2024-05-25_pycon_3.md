+++
title = '[from Florence import PyCon] Third day notes'
date = 2024-05-25T23:58:22+02:00
type = 'post'
+++

# [KEYNOTE] Myths and fairy tales around Python performance
by [Antonio Cuni](https://pyscript.com/@antocuni/) - [slides](https://antocuni.pyscriptapps.com/pycon-it-2024-performance-myths/latest/)

Python is slow. Full stop.
When optimizing a part of code, you could follow the Pareto principle: you can find that 20% of code which accounts for the 80% of total runtime, and then optimize that part.
But then, after the optimization, you'll find yourself with the remaining 80% of the code which now accounts for a big, not negligible part of the total runtime!

Python is slow because of its dynamicity. You can have dynamics types, at the cost of having a very very very long Python bytecode.
Also, memory management and pointers are a major source of Python slowness; on the other side, you don't have to tackle data allocation in memory when writing code.

Some interesting tools met in this talk:
[pyscript.com](https://pyscript.com/) - a free platform that lets you create web applications with a suite of web-ready Python libraries, can be used to host and share slides
[pdb++](https://github.com/pdbpp/pdbpp) - a drop-in replacement for [pdb](https://docs.python.org/3/library/pdb.html) (Python Debugger)
[spylang/spy](https://4897a01d-e56f-47fa-814f-70c7c1e11730.pyscriptapps.com/8bd8148e-fbdc-49f9-9ec2-0b01f432ef90/latest/) - a static Python to WASM compiler - [github repo](https://github.com/spylang/spy)


# [TALK] Preservare la Privacy dei Dati Personali nell'Era dell'IA: Un Approccio Pratico con Nerpii
by Simona Mazzarino - ClearBoxAI - [slides](https://github.com/simonamazzarino/pycon_slides)

[NERPII](https://github.com/Clearbox-AI/nerpii) (Named Entity Recognition for Personal Identifier Information) is an open source library to recognize PII in a text/database and to replace them with synthetic data. There's no direct application of this ML models to Eoliann's maps, but maybe when dealing with customer data in the future (I can't figure out a use case).

These synthetic data aren't 1-to-1 copies of the original data, but they are generated and they have the same statistics (such as with the same distribution) of original data.
Synthetic data are generated with GAE/GANN. As you're generating data, you can augment your original dataset, while preserving original data privacy.

# [TALK] Sii il cambiamento che vuoi vedere nel mondo
by Mara Marzocchi - [Codemotion](https://www.codemotion.com/) - mara.marzocchi@gmail.com

[Robert Owen](https://en.wikipedia.org/wiki/Robert_Owen) in the early 19th century founded a wellbeing model for workers in the textile industry.
Gandhi reacted to English domination although he was shy and not good in public speaking.

Embody the change and inspire others.
Start even if you're alone... (Robert and Gandhi were)
...even if you're not a leader... (just need to get to the tipping point and everyone will join)
...and remember: every step counts! (done is better than perfect)

The [manifesto italiano per l'uguaglianza delle ragazze e delle donne nella tecnologia](https://www.manifestoitalianodonnetecnologia.com/) has been published. Sign and reach 1000 signatures together!

# [TALK] Python-friendly cloud infrastructure management
by Roman Prykhodchenko - Hauki Tech - roman@hauki.tech

Developers don't like infrastructure. Why?
Because infra is complex.
And because devs are isolated, they are now far from infrastructure (back in time, you as a developer were able to understand deployment as you simply needed to copy/paste files from your local PC to your local server).

Developers *should not* avoid infrastructure, so:
- communicate with operations people;
- break the silos and work together.

Hashicorp's Terraform is a provider agnostic Infrastructure as a Code service. With Terraform, you write `manifest` files, where you descrive the desired infrastructure state; you have `state` files, where there's the description of the actual infrastructure state; and there there's the "real" infrastructure by your cloud provider.
You write declarative code, therefore you describe the infrastructure you want, but Terraform take care of how to build that desired infrastructure.
Very important thing to note: Terraform uses its HCL, which is Terraform's peculiar language. This is not Python. This creates barriers between developers and the infrastructure.

Terraform provides the Cloud Development Kit (CDK), with which you can write `state` files with Python! An example code shown at the talk is available at [Hauki Tech GitHub page](https://github.com/haukitech/pyconit24-terraform-example).
AWS provides reference modules for sane default infrastructure pieces.
AWS provides also reference architectures for typical use cases.

Remember that IaC files should be as simple as possible: do not convolute them with strange Python loops!

You can also test the created infrastructure with pytest. How?

Devs should have a convenient way to put to production their code on a first try.

# [TALK] Snakes and Ladders: The Ups and Downs of Python Development with AWS Lambda
by Kristi Perreault

To get good everyday tools to work with AWS Lambdas with Python, use the Lambda Powertools library (we already use them): you'll get Tracers, Metrics, Loggers and Event Handlers.

Python is one of the language with the shortest cold start time in Lambdas.

She suggested to use [AWS CodeDeploy](https://aws.amazon.com/codedeploy/) and [AWS CodePipeline](https://aws.amazon.com/codepipeline/).

To test locally lambdas, use Moto or [Python-lambda-local](https://pypi.org/project/python-lambda-local/) (this second one is probably not available for Lambdas running containers).

# [KEYNOTE] Stay Close to the Metal
by Vicki Boykis - Mozilla AI

Ellen Ullman's book *Close to the Machine*. 
Felienne Hermans's book *The programmer's brain*.

Unix's philosophy: each program should do one thing and do it well; for new tasks, start afresh.

Some tools mentioned during the keynote:
- [Ray](https://docs.ray.io/en/master/index.html) - open source framework to build and scale ML and Python applications easily 
- [vLLM](https://docs.vllm.ai/en/latest/) - fast and easy-to-use library for LLM inference and serving
- [llamafile](https://github.com/Mozilla-Ocho/llamafile) - lets you distribute and run LLMs with a single file (by Mozilla)
- [lm-buddy](https://github.com/mozilla-ai/lm-buddy) - a collection of jobs for finetuning and evaluating open-source (large) language models; released by [mozilla.ai](https://www.mozilla.ai/) (apparently, a startup spinoff of Mozilla).